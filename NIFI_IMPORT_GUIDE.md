# ğŸ“¥ Guide d'Import du Flow NiFi

## ğŸ¯ Vue d'ensemble

Vous avez un flow NiFi prÃ©-configurÃ© qui :
- âœ… Lit le fichier CSV `Airline_Delay_Cause`
- âœ… SÃ©pare les lignes
- âœ… Convertit CSV â†’ JSON
- âœ… Ajoute un timestamp
- âœ… Envoie Ã  Kafka (topic: airline-delays)

## ğŸ“‹ MÃ©thode 1 : Import via l'Interface Web (RECOMMANDÃ‰)

### Ã‰tape 1 : AccÃ©der Ã  NiFi
1. Ouvrir votre navigateur
2. Aller Ã  : **http://localhost:8080/nifi**
3. Login avec :
   - **Username** : `admin`
   - **Password** : `adminadminadmin`

### Ã‰tape 2 : Importer le Flow
1. **Clic droit** sur le canvas (la zone de travail blanche)
2. SÃ©lectionner **"Upload Process Group"**
3. Cliquer sur **"Select Process Group"**
4. Naviguer vers : `C:\Users\hp\ynov-pfe\scripts\airlineflow (1).json`
5. Cliquer sur **"Upload"**
6. Glisser et dÃ©poser le Process Group sur le canvas

### Ã‰tape 3 : Configurer le GetFile Processor
1. **Double-cliquer** sur le Process Group "airlineflow"
2. Localiser le processeur **"GetFile"** (rectangle bleu)
3. **Clic droit** sur GetFile â†’ **Configure**
4. Onglet **"Properties"**
5. VÃ©rifier/Modifier :
   - **Input Directory** : `/data`
   - **File Filter** : `Airline_Delay_Cause.*\.csv`
   - **Keep Source File** : `true`
6. Cliquer **Apply**

### Ã‰tape 4 : Activer les Controller Services
1. **Clic droit** sur le canvas â†’ **Configure**
2. Aller Ã  l'onglet **"Controller Services"**
3. Vous verrez 2 services :
   - **CSVReader** (lit le CSV)
   - **JsonRecordSetWriter** (Ã©crit en JSON)
4. Pour chaque service :
   - Cliquer sur l'icÃ´ne **Ã©clair** (âš¡) Ã  droite
   - SÃ©lectionner **"Enable"**
   - Attendre que le statut devienne **"Enabled"** (vert)
5. Cliquer **Close**

### Ã‰tape 5 : DÃ©marrer le Flow
1. **Clic droit** sur le Process Group "airlineflow"
2. SÃ©lectionner **"Start"**

OU

1. Ouvrir le Process Group (double-clic)
2. SÃ©lectionner tous les processeurs : **Ctrl + A**
3. **Clic droit** â†’ **Start**

### Ã‰tape 6 : Surveiller l'ExÃ©cution
- Les chiffres sur les connexions indiquent le flux de donnÃ©es
- Les processeurs actifs ont un symbole â–¶ï¸ vert
- VÃ©rifier les bulletins en haut Ã  droite (icÃ´ne ğŸ“‹)

## ğŸ“‹ MÃ©thode 2 : Import via Script PowerShell

```powershell
.\import_nifi_flow.ps1
```

Puis suivre les instructions affichÃ©es.

## ğŸ”§ Configuration du Flow

### Structure du Flow
```
GetFile
   â†“
SplitText (sÃ©pare les lignes)
   â†“
ConvertRecord (CSV â†’ JSON)
   â†“
UpdateAttribute (ajoute timestamp)
   â†“
PublishKafka (envoie Ã  Kafka)
   â†“
Success/Failure Funnels
```

### Configuration Kafka
- **Kafka Brokers** : `kafka:29092` (rÃ©seau Docker interne)
- **Topic** : `airline-delays`
- **Compression** : gzip
- **Delivery Guarantee** : Best Effort (acks=0)

### Configuration CSV
- **Format** : RFC-4180
- **Separator** : `,`
- **Header** : PremiÃ¨re ligne traitÃ©e comme header
- **Encoding** : UTF-8

## âœ… VÃ©rification

### 1. VÃ©rifier que NiFi envoie des donnÃ©es
```bash
# Dans NiFi, regarder les compteurs sur les connexions
# Le processeur PublishKafka doit montrer des messages envoyÃ©s
```

### 2. VÃ©rifier les messages dans Kafka
```bash
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic airline-delays --max-messages 5
```

### 3. VÃ©rifier l'insertion dans ClickHouse
```bash
# S'assurer que script1 est en cours d'exÃ©cution
python scripts/script1_kafka_to_clickhouse.py

# VÃ©rifier les donnÃ©es
docker exec clickhouse clickhouse-client --query "SELECT count(*) FROM airline_data.flights"
```

## ğŸ” DÃ©pannage

### ProblÃ¨me : Le fichier n'est pas trouvÃ©
**Solution** :
```bash
# VÃ©rifier que le fichier existe dans le conteneur
docker exec nifi ls -la /data/

# Le fichier doit Ãªtre : /data/Airline_Delay_Cause - Airline_Delay_Cause.csv
```

### ProblÃ¨me : Les Controller Services ne s'activent pas
**Solution** :
1. VÃ©rifier qu'il n'y a pas d'erreurs dans les propriÃ©tÃ©s
2. Dans l'onglet Controller Services, cliquer sur l'icÃ´ne "âš ï¸" pour voir l'erreur
3. Corriger les propriÃ©tÃ©s manquantes

### ProblÃ¨me : Kafka n'est pas accessible
**Solution** :
1. VÃ©rifier la configuration de PublishKafka
2. S'assurer d'utiliser `kafka:29092` (pas `localhost:9092`)
3. VÃ©rifier que Kafka est actif : `docker ps | grep kafka`

### ProblÃ¨me : Aucune donnÃ©e ne circule
**Solution** :
1. VÃ©rifier les bulletins (icÃ´ne ğŸ“‹ en haut Ã  droite)
2. Consulter les logs : `docker logs nifi --tail 100`
3. VÃ©rifier le processeur GetFile :
   - Est-il en cours d'exÃ©cution ?
   - Le rÃ©pertoire est-il correct ?
   - Le fichier est-il prÃ©sent ?

## ğŸ¯ AprÃ¨s l'Import

### ArrÃªter le Simulateur
Si vous utilisez NiFi, arrÃªtez le simulateur Python :
```bash
# Appuyer sur Ctrl+C dans le terminal oÃ¹ tourne le simulateur
```

### Garder Script1 Actif
Le script `script1_kafka_to_clickhouse.py` doit continuer Ã  tourner :
```bash
python scripts/script1_kafka_to_clickhouse.py
```

### Architecture Finale
```
CSV â†’ NiFi â†’ Kafka â†’ Script1 â†’ ClickHouse â†’ Script2 â†’ MongoDB
```

## ğŸ“Š Interfaces de Monitoring

- **NiFi** : http://localhost:8080/nifi
- **Kafka UI** : http://localhost:8081
- **ClickHouse** : http://localhost:8123/play
- **Mongo Express** : http://localhost:8082

## ğŸ’¡ Conseils

1. **DÃ©bit** : Ajustez le "Run Schedule" de GetFile (par dÃ©faut 60 sec)
2. **Logs** : Surveillez les bulletins NiFi pour les erreurs
3. **Backpressure** : Si les connexions se remplissent, augmentez les seuils
4. **Performance** : NiFi consomme ~2-4 GB RAM, surveillez les ressources

## ğŸ”„ Comparaison Simulateur vs NiFi

| Aspect | Simulateur | NiFi |
|--------|-----------|------|
| Ressources | LÃ©ger (~100 MB) | Lourd (~2-4 GB) |
| Configuration | Code Python | Interface graphique |
| DÃ©marrage | ImmÃ©diat | 2-3 minutes |
| Monitoring | Logs | Interface visuelle |
| FlexibilitÃ© | Code modifiable | Processeurs configurables |
| Production | Tests/Dev | Production |

## ğŸ“ RÃ©sumÃ©

1. âœ… AccÃ©der Ã  http://localhost:8080/nifi
2. âœ… Importer `airlineflow (1).json`
3. âœ… Activer les Controller Services
4. âœ… DÃ©marrer le flow
5. âœ… VÃ©rifier dans Kafka UI et ClickHouse

**Le flow est prÃªt Ã  l'emploi !** ğŸ‰
