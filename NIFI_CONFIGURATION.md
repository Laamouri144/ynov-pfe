# Configuration NiFi pour le Pipeline de Donn√©es

## üìã Pr√©requis
- NiFi est d√©marr√© : http://localhost:8080/nifi
- Credentials : admin / adminadminadmin
- Kafka est accessible sur localhost:9092

## üîß Configuration du Flow NiFi

### √âtape 1 : Acc√©der √† NiFi
1. Ouvrir http://localhost:8080/nifi dans votre navigateur
2. Se connecter avec :
   - Username: `admin`
   - Password: `adminadminadmin`

### √âtape 2 : Cr√©er le Flow de Lecture CSV ‚Üí Kafka

#### A. Ajouter un Processeur GetFile
1. Glissez l'ic√¥ne **Processor** sur le canvas
2. Cherchez et s√©lectionnez **GetFile**
3. Configurez :
   - **Input Directory** : `/data`
   - **File Filter** : `Airline_Delay_Cause.*\.csv`
   - **Keep Source File** : `true` (pour ne pas supprimer le fichier)
   - **Polling Interval** : `10 sec`
   - **Batch Size** : `10`

#### B. Ajouter SplitText (pour lire ligne par ligne)
1. Ajoutez un processeur **SplitText**
2. Configurez :
   - **Line Split Count** : `1`
   - **Header Line Count** : `1`
   - **Remove Trailing Newlines** : `true`

#### C. Ajouter ConvertRecord (CSV vers JSON)
1. Ajoutez un processeur **ConvertRecord**
2. Cr√©ez un **CSVReader** Controller Service :
   - Type : `CSVReader`
   - Schema Access Strategy : `Use String Fields From Header`
   - Treat First Line as Header : `true`
3. Cr√©ez un **JsonRecordSetWriter** Controller Service :
   - Type : `JsonRecordSetWriter`
   - Schema Write Strategy : `Do Not Write Schema`
   - Output Grouping : `One Line Per Object`

#### D. Ajouter UpdateAttribute (ajouter timestamp)
1. Ajoutez un processeur **UpdateAttribute**
2. Ajoutez une propri√©t√© :
   - **ingestion_timestamp** : `${now():format('yyyy-MM-dd HH:mm:ss')}`

#### E. Ajouter PublishKafka_2_6
1. Ajoutez un processeur **PublishKafka_2_6**
2. Configurez :
   - **Kafka Brokers** : `kafka:29092`
   - **Topic Name** : `airline-delays`
   - **Delivery Guarantee** : `Best Effort`
   - **Message Key Field** : (laisser vide)
   - **Use Transactions** : `false`

### √âtape 3 : Connecter les Processeurs
1. GetFile ‚Üí SplitText (relation: success)
2. SplitText ‚Üí ConvertRecord (relation: splits)
3. ConvertRecord ‚Üí UpdateAttribute (relation: success)
4. UpdateAttribute ‚Üí PublishKafka (relation: success)
5. Pour chaque processeur, connecter les relations d'erreur (failure) vers un processeur LogAttribute ou auto-terminate

### √âtape 4 : Activer les Controller Services
1. Clic droit sur le canvas ‚Üí Configure
2. Onglet **Controller Services**
3. Activer tous les services (CSVReader, JsonRecordSetWriter)

### √âtape 5 : D√©marrer le Flow
1. S√©lectionnez tous les processeurs (Ctrl+A)
2. Clic droit ‚Üí Start
3. V√©rifiez que les donn√©es circulent en regardant les compteurs sur les connexions

## üîç V√©rification

### V√©rifier que les donn√©es arrivent dans Kafka
```bash
docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic airline-delays --from-beginning --max-messages 5
```

### V√©rifier que script1 consomme les donn√©es
Le script `script1_kafka_to_clickhouse.py` doit √™tre en cours d'ex√©cution :
```bash
python scripts/script1_kafka_to_clickhouse.py
```

### V√©rifier dans ClickHouse
```bash
docker exec clickhouse clickhouse-client --query "SELECT count(*) FROM airline_data.flights"
```

## üìä Sch√©ma du CSV

Les colonnes du fichier CSV sont :
- year, month, carrier, carrier_name
- airport, airport_name
- arr_flights, arr_del15
- carrier_ct, weather_ct, nas_ct, security_ct, late_aircraft_ct
- arr_cancelled, arr_diverted, arr_delay
- carrier_delay, weather_delay, nas_delay, security_delay, late_aircraft_delay

## ‚ö†Ô∏è R√©solution de Probl√®mes

### Le fichier n'est pas trouv√©
- V√©rifiez que le CSV est bien copi√© : `docker exec nifi ls -la /data/`
- Le chemin complet est : `/data/Airline_Delay_Cause - Airline_Delay_Cause.csv`

### Kafka n'est pas accessible
- Utilisez `kafka:29092` depuis NiFi (r√©seau Docker interne)
- NE PAS utiliser `localhost:9092` depuis NiFi

### Les donn√©es ne passent pas
- V√©rifiez les bulletins (ic√¥ne liste) en haut √† droite de NiFi
- Consultez les logs : `docker logs nifi --tail 100`

## üéØ Avantages de NiFi vs Simulateur

**NiFi :**
- ‚úÖ Interface graphique professionnelle
- ‚úÖ Monitoring en temps r√©el
- ‚úÖ Gestion des erreurs sophistiqu√©e
- ‚úÖ Backpressure automatique
- ‚ùå Plus lourd (2-4 GB RAM)

**Simulateur Python :**
- ‚úÖ L√©ger et rapide
- ‚úÖ Code facile √† comprendre/modifier
- ‚úÖ Parfait pour d√©veloppement/tests
- ‚ùå Moins "professionnel" visuellement

## üí° Recommandation

Pour un PFE, utilisez :
1. **Simulateur** pendant le d√©veloppement et les tests
2. **NiFi** pour la d√©monstration finale (impact visuel)
3. Documentez les deux approches dans votre rapport
