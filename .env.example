# Environment Configuration
# Copy this file to .env and update with your actual values

# ============================================
# PC CONFIGURATION
# ============================================
# Set this to PC1 or PC2 depending on which machine you're on
PC_ROLE=PC1

# ============================================
# NETWORK CONFIGURATION
# ============================================
# PC1 IP Address (Data Ingestion PC)
PC1_IP=192.168.1.100

# PC2 IP Address (Analytics PC)
PC2_IP=192.168.1.101

# ============================================
# KAFKA CONFIGURATION (PC1)
# ============================================
KAFKA_HOST=${PC1_IP}
KAFKA_PORT=9092
KAFKA_TOPIC=airline-delays
ZOOKEEPER_HOST=${PC1_IP}
ZOOKEEPER_PORT=2181

# ============================================
# CLICKHOUSE CONFIGURATION (PC2)
# ============================================
CLICKHOUSE_HOST=${PC2_IP}
CLICKHOUSE_HTTP_PORT=8123
CLICKHOUSE_NATIVE_PORT=9000
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=
CLICKHOUSE_DATABASE=airline_data

# ============================================
# MONGODB CONFIGURATION (PC2)
# ============================================
MONGODB_HOST=${PC2_IP}
MONGODB_PORT=27017
MONGODB_DATABASE=airline_cache
MONGODB_COLLECTION=aggregated_delays
MONGODB_USER=
MONGODB_PASSWORD=

# ============================================
# NIFI CONFIGURATION (PC1)
# ============================================
NIFI_HOST=${PC1_IP}
NIFI_PORT=8080
NIFI_VERSION=1.23.2

# ============================================
# PYTHON SCRIPT CONFIGURATION
# ============================================
# Script 1: Kafka to ClickHouse
BATCH_SIZE=1000
CONSUMER_GROUP_ID=airline-consumer-group
AUTO_OFFSET_RESET=earliest

# Script 2: ClickHouse to MongoDB Cache
CACHE_UPDATE_INTERVAL=300  # seconds (5 minutes)
AGGREGATION_PERIOD=daily   # daily, hourly, monthly

# Script 3: ML Training
ML_FRAMEWORK=spark  # spark, dask, sklearn
MODEL_PATH=./models
TRAINING_SCHEDULE=daily
DATA_SPLIT_RATIO=0.8

# ============================================
# STREAMLIT CONFIGURATION
# ============================================
STREAMLIT_PORT=8501
STREAMLIT_HOST=0.0.0.0
STREAMLIT_REFRESH_INTERVAL=5  # seconds

# ============================================
# LOGGING
# ============================================
LOG_LEVEL=INFO
LOG_FILE=./logs/pipeline.log

# ============================================
# DATA PATHS
# ============================================
DATA_RAW_PATH=./data/raw
DATA_PROCESSED_PATH=./data/processed
CSV_FILE_PATH=./Airline_Delay_Cause - Airline_Delay_Cause.csv

# ============================================
# DOCKER CONFIGURATION
# ============================================
COMPOSE_PROJECT_NAME=airline-pipeline
